### Environment
# Queue system to use (sqs or mongo)
queueService = mongo
# Storage service to write the results (s3 or mongo)
storageService = mongo
# Place of origin of input files (s3 or url)
fileOrigin = url


### AWS Access Properties
# Your AWS Access Key (Update with your key)
#awsAccessKey = <edit>
# Your AWS Secret Key (Update with your key)
#awsSecretKey = <edit>


### AWS S3 Properties
# Your S3 Bucket name for results
#resultBucket = mongo
# Your S3 Bucket for the code to be deployed on the EC2 instances
#deployBucket = <edit>
# AWS S3 data bucket prefix for public datasets (No need to change, unless you want to process other data than CC)
dataBucket = commoncrawl
# Common Crawl data bucket (Change depending on the dataset you want to process)
# Name of the jar of the WDC Framework, after uploading to S3 (No need to change)
#deployFilename = amef.jar


### AWS EC2 Properties
# Endpoint of the EC2 API (No need to change, unless you want to launch your instances within another region)
#ec2endpoint = ec2.us-east-1.amazonaws.com
# AMI which will be launched (Make sure the AMI you select has e.g. the write system language, which can influence your reading and writing of files.)
#ec2ami = ami-07d0cf3af28718ef8
# Please check the available instance descriptions for the right instance type for your process. (Make sure #CPU, #RAM and #DISC is enough for your job!)
# Pricing: https://aws.amazon.com/ec2/pricing/
# EC2 Instant Types: https://aws.amazon.com/ec2/instance-types/
#ec2instancetype = c5.large
# Memory which will be given to Java Process, when executing the .jar on each machine (java -Xmx)
#javamemory = 5G
# Name of the key pair you can use to access the instances. (Update with your key)
#ec2keypair = <edit>


### WDC Extraction Framework Properties
# the class you want to use to process your files. This class needs to implement amef.processor.FileProcessor
processorClass = amef.processor.SchemaWarcProcessor


### MongoDB Properties
# Ip or domain of the mongodb server
mongoUrl = localhost
# Port of the mongodb server
mongoPort = 27017
# Database name
mongoDB = amef

### Local processing
parallelFiles = 4


### Queue Properties
## Common
# Name of the queue (No need to change, unless you are running other SQS with a similar name)
jobQueueName = jobs
# Data Suffix for file processing and filtering (Change according to the files you want to put into the queue, e.g. .warc.gz, .arc.gz, ...)
dataSuffix = .warc.gz
# Batch size for filling the queue (No need to change)
batchsize = 10

## AWS
# AWS Queue endpoint (No need to change)
#queueEndpoint = sqs.us-east-1.amazonaws.com
# Time a thread waits a file to be processed before discarding it
jobTimeLimit = 1000
